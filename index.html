<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Nailosophy Lens - AR Try-On</title>
  <style>
    body { margin: 0; overflow: hidden; background: #000; color: white; font-family: sans-serif; }
    canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 5; pointer-events: none; }
    video { width: 100vw; height: 100vh; object-fit: cover; }
    #status { 
      position: absolute; top: 20px; left: 20px; 
      background: rgba(0,0,0,0.8); padding: 10px; border-radius: 8px;
      z-index: 100; font-size: 11px; border: 1px solid #444;
      max-width: 80%; word-break: break-all;
    }
    .controls {
      position: absolute; bottom: 80px; left: 50%; transform: translateX(-50%);
      z-index: 100; background: rgba(0,0,0,0.6); padding: 15px; border-radius: 15px;
      display: flex; flex-direction: column; gap: 10px; width: 70%;
    }
    .controls label { font-size: 12px; margin-bottom: 5px; display: block; }
    .controls input { width: 100%; }
    #flip-camera {
      position: absolute; bottom: 20px; right: 20px; 
      z-index: 100; padding: 15px; background: white; 
      border-radius: 50%; border: none; font-size: 24px;
    }
  </style>
</head>
<body>
  <div id="status">Booting...</div>
  <div class="controls">
    <div>
      <label>Nail Width</label>
      <input type="range" id="widthScale" min="0.1" max="10.0" step="0.1" value="1.0">
    </div>
    <div>
      <label>Nail Length</label>
      <input type="range" id="lengthScale" min="0.1" max="10.0" step="0.1" value="1.0">
    </div>
  </div>
  <button id="flip-camera">ðŸ”„</button>
  <video id="video" playsinline></video>
  <canvas id="overlay"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>

  <script>
    const log = (msg) => {
      console.log(msg);
      document.getElementById('status').innerText = msg;
    };

    window.onerror = (m, l) => log(`Err: ${m} @ ${l}`);

    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('overlay');
    const flipBtn = document.getElementById('flip-camera');
    const widthSlider = document.getElementById('widthScale');
    const lengthSlider = document.getElementById('lengthScale');

    let facingMode = 'environment';
    let cameraInstance = null;
    let handsInstance = null;

    // --- Three.js ---
    const scene = new THREE.Scene();
    const threeCamera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.01, 1000);
    const renderer = new THREE.WebGLRenderer({ canvas: canvasElement, alpha: true, antialias: true });
    renderer.setSize(window.innerWidth, window.innerHeight);

    scene.add(new THREE.AmbientLight(0xffffff, 1.0));
    const dirLight = new THREE.DirectionalLight(0xffffff, 0.8);
    dirLight.position.set(0, 5, 5);
    scene.add(dirLight);

    const nailGroup = new THREE.Group();
    scene.add(nailGroup);

    // é»˜è®¤ä¿åº•æ–¹å— (ç»¿è‰²)
    const fallbackMesh = new THREE.Mesh(
      new THREE.BoxGeometry(0.02, 0.04, 0.01),
      new THREE.MeshStandardMaterial({ color: 0x00ff00 })
    );
    nailGroup.add(fallbackMesh);

    const loader = new THREE.GLTFLoader();
    // ä½¿ç”¨ç›¸å¯¹è·¯å¾„å°è¯•åŠ è½½æœ¬åœ°æŽ¨é€çš„æ¨¡åž‹
    loader.load('./nail.glb', (gltf) => {
      log('GLB Loaded Successfully');
      nailGroup.clear(); // ç§»é™¤ç»¿è‰²æ–¹å—
      const model = gltf.scene;
      model.rotation.set(0, 0, 0); 
      nailGroup.add(model);
    }, undefined, (e) => {
      log('GLB Load Failed, using Green Box. Error: ' + e.message);
    });

    function onResults(results) {
      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];
        const tip = landmarks[8];
        const dip = landmarks[7];

        const offsetRatio = 0.85;
        const nailCenterX = tip.x + (dip.x - tip.x) * offsetRatio;
        const nailCenterY = tip.y + (dip.y - tip.y) * offsetRatio;
        const manualYDown = 0.02;

        let x = (nailCenterX * 2 - 1);
        let y = -(nailCenterY * 2 - 1 + manualYDown);
        if (facingMode === 'user') x = -x; 

        const actualAspect = canvasElement.clientWidth / canvasElement.clientHeight;
        nailGroup.position.set(x * actualAspect, y, -0.5); // ç¨å¾®é è¿‘é•œå¤´ä¸€ç‚¹ç‚¹

        const dx = tip.x - dip.x;
        const dy = tip.y - dip.y;
        let angle = Math.atan2(dy, (facingMode === 'user') ? -dx : dx);
        nailGroup.rotation.z = -angle - Math.PI/2;

        const handSize = Math.sqrt(Math.pow(landmarks[0].x - landmarks[9].x, 2) + Math.pow(landmarks[0].y - landmarks[9].y, 2));
        const userWidth = parseFloat(widthSlider.value);
        const userLength = parseFloat(lengthSlider.value);

        // è°ƒæ•´ baseScale é€»è¾‘ï¼Œå¢žå¤§åˆå§‹å€¼
        const baseScale = handSize * 0.5; 
        nailGroup.scale.set(
            baseScale * userWidth, 
            baseScale * userLength, 
            baseScale * userWidth
        );

        log(`Scale: ${baseScale.toFixed(3)} | Hands: 1`);
        nailGroup.visible = true;
      } else {
        nailGroup.visible = false;
        log('Hands: 0');
      }
      renderer.render(scene, threeCamera);
    }

    async function init() {
        try {
            log('Initializing Hands...');
            const HandsClass = window.Hands || (window.mpHands && window.mpHands.Hands);
            handsInstance = new HandsClass({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
            });
            handsInstance.setOptions({
                maxNumHands: 1,
                modelComplexity: 0,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            handsInstance.onResults(onResults);

            log('Starting Camera...');
            const CameraClass = window.Camera || (window.mpCamera && window.mpCamera.Camera);
            cameraInstance = new CameraClass(videoElement, {
                onFrame: async () => {
                    if (handsInstance) await handsInstance.send({image: videoElement});
                },
                facingMode: facingMode,
                width: 640,
                height: 480
            });
            await cameraInstance.start();
            log('AR Active.');
        } catch (err) {
            log('Init Error: ' + err.message);
        }
    }

    flipBtn.addEventListener('click', async () => {
      facingMode = (facingMode === 'user') ? 'environment' : 'user';
      videoElement.style.transform = (facingMode === 'user') ? 'scaleX(-1)' : 'scaleX(1)';
      if (cameraInstance) await cameraInstance.stop();
      await init();
    });

    window.addEventListener('resize', () => {
      renderer.setSize(window.innerWidth, window.innerHeight);
      threeCamera.aspect = window.innerWidth / window.innerHeight;
      threeCamera.updateProjectionMatrix();
    });

    init();
  </script>
</body>
</html>
