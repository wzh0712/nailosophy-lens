<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Nailosophy Lens - Pro AR</title>
  <style>
    body { margin: 0; overflow: hidden; background: #000; color: white; font-family: sans-serif; }
    canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 5; pointer-events: none; }
    video { width: 100vw; height: 100vh; object-fit: cover; }
    #status { 
      position: absolute; top: 20px; left: 20px; 
      background: rgba(0,0,0,0.8); padding: 10px; border-radius: 8px;
      z-index: 100; font-size: 11px; border: 1px solid #444;
      max-width: 80%; word-break: break-all;
    }
    .controls {
      position: absolute; bottom: 80px; left: 50%; transform: translateX(-50%);
      z-index: 100; background: rgba(0,0,0,0.6); padding: 15px; border-radius: 15px;
      display: flex; flex-direction: column; gap: 10px; width: 70%;
    }
    .controls label { font-size: 12px; margin-bottom: 5px; display: block; }
    .controls input { width: 100%; }
    #flip-camera {
      position: absolute; bottom: 20px; right: 20px; 
      z-index: 100; padding: 15px; background: white; 
      border-radius: 50%; border: none; font-size: 24px;
    }
  </style>
</head>
<body>
  <div id="status">Booting...</div>
  <div class="controls">
    <div>
      <label>Width</label>
      <input type="range" id="widthScale" min="0.1" max="10.0" step="0.1" value="1.0">
    </div>
    <div>
      <label>Length</label>
      <input type="range" id="lengthScale" min="0.1" max="10.0" step="0.1" value="1.0">
    </div>
  </div>
  <button id="flip-camera">ðŸ”„</button>
  <video id="video" playsinline></video>
  <canvas id="overlay"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>

  <script>
    const log = (msg) => {
      console.log(msg);
      document.getElementById('status').innerText = msg;
    };

    window.onerror = (m, l) => log(`Err: ${m} @ ${l}`);

    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('overlay');
    const flipBtn = document.getElementById('flip-camera');
    const widthSlider = document.getElementById('widthScale');
    const lengthSlider = document.getElementById('lengthScale');

    let facingMode = 'environment';
    let cameraInstance = null;
    let handsInstance = null;

    // --- Three.js ---
    const scene = new THREE.Scene();
    const threeCamera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.01, 1000);
    const renderer = new THREE.WebGLRenderer({ canvas: canvasElement, alpha: true, antialias: true });
    renderer.setSize(window.innerWidth, window.innerHeight);

    scene.add(new THREE.AmbientLight(0xffffff, 1.0));
    const dirLight = new THREE.DirectionalLight(0xffffff, 0.8);
    dirLight.position.set(0, 5, 5);
    scene.add(dirLight);

    const nailGroup = new THREE.Group();
    scene.add(nailGroup);

    const loader = new THREE.GLTFLoader();
    loader.load('./nail.glb', (gltf) => {
      log('GLB Loaded');
      nailGroup.clear();
      const model = gltf.scene;
      model.rotation.set(0, 0, 0); 
      nailGroup.add(model);
    }, undefined, (e) => {
      log('GLB Failed. Error: ' + e.message);
      // Fallback green box
      nailGroup.add(new THREE.Mesh(new THREE.BoxGeometry(0.02, 0.04, 0.01), new THREE.MeshStandardMaterial({ color: 0x00ff00 })));
    });

    // SMOOTHING STATE
    let targetPos = new THREE.Vector3();
    let currentPos = new THREE.Vector3();
    const lerpFactor = 0.35; // è¶Šå¤§è¶Šè·Ÿæ‰‹ï¼Œè¶Šå°è¶Šå¹³æ»‘

    function onResults(results) {
      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];
        const tip = landmarks[8];
        const dip = landmarks[7];

        // --- NEW TRACKING LOGIC ---
        // 1. Calculate center point between joint and tip
        const nailX = (tip.x + dip.x) / 2;
        const nailY = (tip.y + dip.y) / 2;

        // 2. Convert to Normalized Device Coordinates (-1 to +1)
        let ndcX = (nailX * 2 - 1);
        let ndcY = -(nailY * 2 - 1);
        if (facingMode === 'user') ndcX = -ndcX;

        // 3. Unproject: Transform screen position to 3D world space
        // This is much more accurate than simple aspect multiplication
        const tempVector = new THREE.Vector3(ndcX, ndcY, 0.5);
        tempVector.unproject(threeCamera);
        const dir = tempVector.sub(threeCamera.position).normalize();
        
        // Use MediaPipe's Z to estimate world distance
        // tip.z is normalized depth from camera, usually very small negative
        const worldDistance = 1.0 + (tip.z * 2.0); 
        targetPos = threeCamera.position.clone().add(dir.multiplyScalar(worldDistance));

        // 4. Smooth movement (LERP)
        nailGroup.position.lerp(targetPos, lerpFactor);

        // 5. Rotation (Lock to Finger Vector)
        const dx = tip.x - dip.x;
        const dy = tip.y - dip.y;
        let angle = Math.atan2(dy, (facingMode === 'user') ? -dx : dx);
        nailGroup.rotation.z = -angle - Math.PI/2;

        // 6. Scale
        const handSize = Math.sqrt(Math.pow(landmarks[0].x - landmarks[9].x, 2) + Math.pow(landmarks[0].y - landmarks[9].y, 2));
        const userWidth = parseFloat(widthSlider.value);
        const userLength = parseFloat(lengthSlider.value);
        const baseScale = handSize * 0.45; 
        nailGroup.scale.set(baseScale * userWidth, baseScale * userLength, baseScale * userWidth);

        nailGroup.visible = true;
        log('Hands: 1 | Smooth: ON');
      } else {
        nailGroup.visible = false;
        log('Hands: 0');
      }
      renderer.render(scene, threeCamera);
    }

    async function init() {
        try {
            log('Initializing Hands...');
            const HandsClass = window.Hands || (window.mpHands && window.mpHands.Hands);
            handsInstance = new HandsClass({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
            });
            handsInstance.setOptions({
                maxNumHands: 1,
                modelComplexity: 0,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            handsInstance.onResults(onResults);

            log('Starting Camera...');
            const CameraClass = window.Camera || (window.mpCamera && window.mpCamera.Camera);
            cameraInstance = new CameraClass(videoElement, {
                onFrame: async () => {
                    if (handsInstance) await handsInstance.send({image: videoElement});
                },
                facingMode: facingMode,
                width: 640,
                height: 480
            });
            await cameraInstance.start();
            log('AR Ready.');
        } catch (err) {
            log('Init Error: ' + err.message);
        }
    }

    flipBtn.addEventListener('click', async () => {
      facingMode = (facingMode === 'user') ? 'environment' : 'user';
      videoElement.style.transform = (facingMode === 'user') ? 'scaleX(-1)' : 'scaleX(1)';
      if (cameraInstance) await cameraInstance.stop();
      await init();
    });

    window.addEventListener('resize', () => {
      renderer.setSize(window.innerWidth, window.innerHeight);
      threeCamera.aspect = window.innerWidth / window.innerHeight;
      threeCamera.updateProjectionMatrix();
    });

    init();
  </script>
</body>
</html>
